# -*- coding: utf-8 -*-
"""MNIST-CNN-keras.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14tNgpWQQ-ke76e5MbB6JfdtrZaXgeCxa

# MNIST with Keras

We will go through the following steps:
1. Importing libraries and the dataset
2. Data preparation
3. Building and understanding CNN architecture
4. Fitting and evaluating the model

## 1. Importing libraries and the dataset
"""

# Utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Tensorflow and keras
import tensorflow as tf
from keras.datasets import mnist

# Parameters

IMG_ROWS = 28
IMG_COLS = 28
NUM_CLASSES = 10
TEST_SIZE = 0.2
RANDOM_STATE = 42

# Model
NO_EPOCHS = 5
BATCH_SIZE = 128
VERBOSE = 1
PATIENCE = 20

# load the dataset into test and train sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)

# Get class distribution

print(pd.Series(y_train).value_counts())

"""## 2. Data preparation

We will get only 20k images for training, to save time.
Also, the pixel values of the images range from 0 through 255. We scale these values to a range 0 to 1 by dividing their values by 255.0.
"""

# get only 20k images for training
idx = np.random.randint(x_train.shape[0], size=20000)
x_train = x_train[idx, :]
y_train = y_train[idx]
x_train, x_test = x_train / 255.0, x_test / 255.0

"""To verify that the data is in the correct format and that we are ready to build and train the network, let's display the first 25 images from the training set and display the class name below each image."""

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[i], cmap=plt.cm.binary)
    plt.xlabel(y_train[i])
plt.show()

"""## 3. Building the model

We will build the network with:
- 2 convolutional layers having 32 and 64 filters respectively
- a max pooling layer
- Flatten the output of the pooling layer to give us a long vector
- full connected dense layer with 128 neurons
- a softmax layer with 10 neurons

To build a model in Keras -> instantiate a `Sequential` model and keep adding `keras.layers` to it. We will also use some dropouts.
"""

model = tf.keras.models.Sequential(
    [
        tf.keras.layers.Conv2D(
            32, (3, 3), activation="relu", input_shape=(IMG_ROWS, IMG_COLS, 1)
        ),
        tf.keras.layers.Conv2D(64, (3, 3), activation="relu"),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Dropout(0.25),
        tf.keras.layers.Flatten(input_shape=(IMG_ROWS, IMG_COLS)),
        tf.keras.layers.Dense(128, activation="relu"),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(NUM_CLASSES, activation="softmax"),
    ]
)
model.summary()

"""Define a loss function for training using `losses.SparseCategoricalCrossentropy`. The loss function takes a vector of ground truth values and a vector of logits and returns a scalar loss for each example. The loss is equal to the negative log probability of the true class -> if the loss is 0, then the model is sure for the correct class."""

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

"""## 4. Fitting and evaluating the model"""

model.compile(optimizer="adam", loss=loss_fn, metrics=["accuracy"])
model.fit(x_train, y_train, epochs=NO_EPOCHS)

"""The `model.evaluate` method checks the model's performance usually on a validation set or test set."""

model.evaluate(x_test, y_test, verbose=2)
